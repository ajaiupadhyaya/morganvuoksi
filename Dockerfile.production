# MorganVuoksi Elite Terminal - Production Dockerfile
# MISSION CRITICAL: Bloomberg-grade production container
# Multi-stage build for optimal performance

# Stage 1: Base Python environment
FROM python:3.11-slim as base

# System dependencies and security hardening
RUN apt-get update && apt-get install -y \
    build-essential \
    curl \
    git \
    gcc \
    g++ \
    libpq-dev \
    libffi-dev \
    libssl-dev \
    pkg-config \
    && rm -rf /var/lib/apt/lists/* \
    && groupadd -r morganvuoksi \
    && useradd -r -g morganvuoksi morganvuoksi

# Python environment optimization
ENV PYTHONUNBUFFERED=1 \
    PYTHONDONTWRITEBYTECODE=1 \
    PIP_NO_CACHE_DIR=1 \
    PIP_DISABLE_PIP_VERSION_CHECK=1

# Stage 2: Dependencies installation
FROM base as dependencies

WORKDIR /app

# Copy dependency files
COPY requirements.txt requirements-dev.txt ./

# Install Python dependencies with optimizations
RUN pip install --upgrade pip setuptools wheel \
    && pip install --no-cache-dir -r requirements.txt \
    && pip install --no-cache-dir torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cpu \
    && pip install --no-cache-dir tensorflow[and-cuda] \
    && pip install --no-cache-dir -r requirements-dev.txt \
    && python -m nltk.downloader punkt vader_lexicon stopwords \
    && python -c "import torch; torch.hub.download_url_to_file('https://github.com/pytorch/hub/raw/master/imagenet_classes.txt', 'imagenet_classes.txt')"

# Stage 3: Application build
FROM dependencies as application

WORKDIR /app

# Copy source code
COPY src/ ./src/
COPY backend/ ./backend/
COPY database/ ./database/
COPY config/ ./config/
COPY *.py ./
COPY *.md ./

# Create necessary directories
RUN mkdir -p /app/logs /app/data /app/models /app/backups \
    && chown -R morganvuoksi:morganvuoksi /app

# Pre-compile Python bytecode
RUN python -m compileall src/ backend/ -b \
    && find . -name '*.pyc' -delete

# Stage 4: API Service
FROM application as api

# Install additional API dependencies
RUN pip install --no-cache-dir \
    uvicorn[standard]==0.24.0 \
    gunicorn==21.2.0 \
    uvloop==0.19.0 \
    httptools==0.6.1

# Copy production configuration
COPY config/production.yaml ./config/
COPY scripts/start_api.sh ./scripts/

# Make scripts executable
RUN chmod +x ./scripts/start_api.sh

# Security: Switch to non-root user
USER morganvuoksi

# Health check
HEALTHCHECK --interval=30s --timeout=10s --start-period=60s --retries=3 \
    CMD curl -f http://localhost:8000/api/v1/health || exit 1

# Expose ports
EXPOSE 8000 9090

# Start command
CMD ["./scripts/start_api.sh"]

# Stage 5: ML Worker Service
FROM application as ml-worker

# Install ML-specific dependencies
RUN pip install --no-cache-dir \
    ray[default]==2.8.0 \
    optuna==3.4.0 \
    hyperopt==0.2.7 \
    bayesian-optimization==1.4.3

# Copy ML worker configuration
COPY config/ml_worker.yaml ./config/
COPY scripts/start_ml_worker.sh ./scripts/

RUN chmod +x ./scripts/start_ml_worker.sh

USER morganvuoksi

CMD ["./scripts/start_ml_worker.sh"]

# Stage 6: Data Pipeline Service
FROM application as data-pipeline

# Install data pipeline dependencies
RUN pip install --no-cache-dir \
    apache-airflow==2.7.3 \
    celery[redis]==5.3.4 \
    flower==2.0.1

# Copy data pipeline configuration
COPY config/airflow.cfg ./config/
COPY dags/ ./dags/
COPY scripts/start_data_pipeline.sh ./scripts/

RUN chmod +x ./scripts/start_data_pipeline.sh

USER morganvuoksi

CMD ["./scripts/start_data_pipeline.sh"]

# Stage 7: Risk Monitor Service
FROM application as risk-monitor

# Copy risk monitoring configuration
COPY config/risk_monitor.yaml ./config/
COPY scripts/start_risk_monitor.sh ./scripts/

RUN chmod +x ./scripts/start_risk_monitor.sh

USER morganvuoksi

# Health check for risk monitoring
HEALTHCHECK --interval=60s --timeout=30s --start-period=120s --retries=3 \
    CMD python -c "import requests; requests.get('http://localhost:8001/health')" || exit 1

EXPOSE 8001

CMD ["./scripts/start_risk_monitor.sh"]

# Stage 8: Final production image
FROM api as production

# Copy all service scripts
COPY --from=ml-worker /app/scripts/start_ml_worker.sh ./scripts/
COPY --from=data-pipeline /app/scripts/start_data_pipeline.sh ./scripts/
COPY --from=risk-monitor /app/scripts/start_risk_monitor.sh ./scripts/

# Production environment variables
ENV ENVIRONMENT=production \
    LOG_LEVEL=INFO \
    WORKERS=4 \
    MAX_REQUESTS=1000 \
    MAX_REQUESTS_JITTER=100 \
    TIMEOUT=120 \
    KEEPALIVE=5 \
    PRELOAD=true

# Labels for container metadata
LABEL maintainer="MorganVuoksi Team" \
      version="1.0.0" \
      description="Production Bloomberg Terminal for Quantitative Finance" \
      environment="production"

# Final security and optimization
USER morganvuoksi
WORKDIR /app

# Default command (can be overridden)
CMD ["./scripts/start_api.sh"]